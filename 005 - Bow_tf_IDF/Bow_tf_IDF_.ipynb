{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis de Texto con Bag of Words y TF-IDF"
      ],
      "metadata": {
        "id": "oXy46nCe4L8o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQDPVffi27MD",
        "outputId": "a2bb892b-9a1a-434d-eccc-2c94c4e9d4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "# Instalamos scikit-learn si no está disponible (puede omitirse si ya está instalado)\n",
        "!pip install scikit-learn\n",
        "\n",
        "# Importamos las bibliotecas necesarias\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer  # Para procesamiento de texto\n",
        "import pandas as pd  # Para manejar estructuras de datos\n",
        "import numpy as np  # Para operaciones matemáticas (no se usa directamente en este código)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos una lista de documentos de ejemplo\n",
        "documentos = [\n",
        "    \"El perro muerde al hombre\",\n",
        "    \"El hombre muerde al perro\",\n",
        "    \"El perro come carne\",\n",
        "    \"El hombre come comida\"\n",
        "]"
      ],
      "metadata": {
        "id": "8H1jrBuF3knH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos los documentos originales para referencia\n",
        "print(\"Nuestro corpus de ejemplo:\")\n",
        "for i, documento in enumerate(documentos):\n",
        "    print(f\"Documento {i}: {documento}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn9S1rjE3m5y",
        "outputId": "992d09bb-cc2b-42ad-c7ad-62a72454627c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nuestro corpus de ejemplo:\n",
            "Documento 0: El perro muerde al hombre\n",
            "Documento 1: El hombre muerde al perro\n",
            "Documento 2: El perro come carne\n",
            "Documento 3: El hombre come comida\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Parte 1: Bag of Words (BoW)\n",
        "\n",
        "# Inicializamos el vectorizador BoW, que convertirá los textos en una representación de frecuencia de palabras\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# Creamos la representación BoW transformando los documentos en una matriz de frecuencias\n",
        "bow_rep = count_vectorizer.fit_transform(documentos)\n",
        "\n",
        "# Mostramos el vocabulario generado: las palabras únicas y sus índices en el modelo\n",
        "print(\"\\nVocabulario generado:\", count_vectorizer.vocabulary_)\n",
        "\n",
        "# Convertimos la matriz BoW en un DataFrame para mejor visualización\n",
        "vocab = count_vectorizer.get_feature_names_out()\n",
        "df_bow = pd.DataFrame(bow_rep.toarray(), columns=vocab)\n",
        "\n",
        "# Mostramos la matriz BoW que indica la frecuencia de cada palabra en los documentos\n",
        "print(\"\\nRepresentación Bag of Words:\")\n",
        "print(df_bow)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__EC-Am-3rdP",
        "outputId": "fb306ddf-4c5f-419c-db8e-7b43751d5df5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulario generado: {'el': 4, 'perro': 7, 'muerde': 6, 'al': 0, 'hombre': 5, 'come': 2, 'carne': 1, 'comida': 3}\n",
            "\n",
            "Representación Bag of Words:\n",
            "   al  carne  come  comida  el  hombre  muerde  perro\n",
            "0   1      0     0       0   1       1       1      1\n",
            "1   1      0     0       0   1       1       1      1\n",
            "2   0      1     1       0   1       0       0      1\n",
            "3   0      0     1       1   1       1       0      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Parte 2: Aplicación de TF-IDF\n",
        "\n",
        "# Inicializamos el vectorizador TF-IDF, que ajusta la importancia de las palabras en el conjunto de documentos\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Creamos la representación TF-IDF transformando los documentos en una matriz ponderada\n",
        "tfidf_rep = tfidf_vectorizer.fit_transform(documentos)\n",
        "\n",
        "# Convertimos la matriz TF-IDF en un DataFrame para mejor visualización\n",
        "df_tfidf = pd.DataFrame(tfidf_rep.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "# Mostramos la matriz TF-IDF que refleja la importancia de cada palabra en el conjunto de documentos\n",
        "print(\"\\nMatriz TF-IDF:\")\n",
        "print(df_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S67h1YfB3uAq",
        "outputId": "8203952e-b056-457a-b360-17fe4513efc5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matriz TF-IDF:\n",
            "        al     carne      come    comida        el    hombre   muerde  \\\n",
            "0  0.51647  0.000000  0.000000  0.000000  0.341846  0.418127  0.51647   \n",
            "1  0.51647  0.000000  0.000000  0.000000  0.341846  0.418127  0.51647   \n",
            "2  0.00000  0.659191  0.519714  0.000000  0.343993  0.000000  0.00000   \n",
            "3  0.00000  0.000000  0.519714  0.659191  0.343993  0.420753  0.00000   \n",
            "\n",
            "      perro  \n",
            "0  0.418127  \n",
            "1  0.418127  \n",
            "2  0.420753  \n",
            "3  0.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conclusión:\n",
        "# - Bag of Words representa textos como matrices de frecuencia de palabras.\n",
        "# - TF-IDF ajusta esas frecuencias para reflejar la importancia de cada término en el conjunto de documentos.\n",
        "# - Ambas técnicas son clave para análisis de texto, clasificación y extracción de información en modelos de aprendizaje automático."
      ],
      "metadata": {
        "id": "K4zY7FNm35QC"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}